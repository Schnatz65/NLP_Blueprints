{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 11: Durchführen von Sentiment-Analysen für Textdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Es werden die Verzeichnisse festgelegt. Wenn Sie mit Google Colab arbeiten: Die erforderlichen Dateien werden kopiert und die erforderlichen Bibliotheken installiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinweise\n",
    "\n",
    "Mit ### ergänzte Code-Zeilen geben Werte an, die angepasst werden können. \n",
    "\n",
    "Transformers Version 3.5.1 muss installiert werden: pip install transformers==3.5.1 \n",
    "\n",
    "Pytorch (oder Tensorflow > 2) muss instaliert werden: pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working on a local system.\n",
      "Files will be searched relative to \"..\".\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    GIT_ROOT = 'https://github.com/blueprints-for-text-analytics-python/blueprints-text/raw/master'\n",
    "    os.system(f'wget {GIT_ROOT}/ch11/setup.py')\n",
    "\n",
    "%run -i setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-Einstellungen laden\n",
    "\n",
    "Allgemeine Importe, Standardwerte für die Formatierung in Matplotlib, Pandas usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     C:\\Users\\kleme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pfad zum Importieren der Blueprint-Packages\n",
    "sys.path.append(BASE_DIR + '/packages')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einführung in den Amazon-Kundenrezensionsdatensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163807</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>A2A8GHFXUG1B28</td>\n",
       "      <td>B0045Z4JAI</td>\n",
       "      <td>Good Decaf... it has a good flavour for a deca...</td>\n",
       "      <td>Nice!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195640</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>A1VU337W6PKAR3</td>\n",
       "      <td>B00K0TIC56</td>\n",
       "      <td>I could not ask for a better system for my sma...</td>\n",
       "      <td>I could not ask for a better system for my sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167820</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>A1Z5TT1BBSDLRM</td>\n",
       "      <td>B0012ORBT6</td>\n",
       "      <td>good product at a good price and saves a trip ...</td>\n",
       "      <td>Four Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104268</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>A4PRXX2G8900X</td>\n",
       "      <td>B005SPI45U</td>\n",
       "      <td>I like the principle of a raw chip - something...</td>\n",
       "      <td>No better alternatives but still tastes bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51961</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>AYETYLNYDIS2S</td>\n",
       "      <td>B00D1HLUP8</td>\n",
       "      <td>Fake China knockoff, you get what you pay for.</td>\n",
       "      <td>Definitely not OEM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  verified      reviewerID        asin  \\\n",
       "163807        5     False  A2A8GHFXUG1B28  B0045Z4JAI   \n",
       "195640        5      True  A1VU337W6PKAR3  B00K0TIC56   \n",
       "167820        4      True  A1Z5TT1BBSDLRM  B0012ORBT6   \n",
       "104268        1     False   A4PRXX2G8900X  B005SPI45U   \n",
       "51961         1      True   AYETYLNYDIS2S  B00D1HLUP8   \n",
       "\n",
       "                                                     text  \\\n",
       "163807  Good Decaf... it has a good flavour for a deca...   \n",
       "195640  I could not ask for a better system for my sma...   \n",
       "167820  good product at a good price and saves a trip ...   \n",
       "104268  I like the principle of a raw chip - something...   \n",
       "51961      Fake China knockoff, you get what you pay for.   \n",
       "\n",
       "                                                  summary  \n",
       "163807                                              Nice!  \n",
       "195640  I could not ask for a better system for my sma...  \n",
       "167820                                         Four Stars  \n",
       "104268       No better alternatives but still tastes bad.  \n",
       "51961                                  Definitely not OEM  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"reviews_5_balanced.json.gz\"\n",
    "file = f\"{BASE_DIR}/data/amazon-product-reviews/reviews_5_balanced.json.gz\" ### real location\n",
    "df = pd.read_json(file, lines=True)\n",
    "df = df.drop(columns=['reviewTime','unixReviewTime']) ###\n",
    "df = df.rename(columns={'reviewText': 'text'}) ###\n",
    "df.sample(5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blueprint 1: Sentiment-Analyse mit lexikonbasierten Ansätzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bing Liu Lexikon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in opinion lexicon 6789\n",
      "Examples of positive words in opinion lexicon ['a+', 'abound', 'abounds', 'abundance', 'abundant']\n",
      "Examples of negative words in opinion lexicon ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words in opinion lexicon',\n",
    "      opinion_lexicon.positive()[:5])\n",
    "print('Examples of negative words in opinion lexicon',\n",
    "      opinion_lexicon.negative()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kleme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Erstellung eines Wörterbuchs für die Bewertung unseres Rezensionstextes\n",
    "# Dieser erste BEfehl braucht nur beim ersten Aufruf durchgeführt werden\n",
    "nltk.download('punkt') ###\n",
    "df.rename(columns={\"reviewText\": \"text\"}, inplace=True)\n",
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Hinzufügen der positiven Wörter zum Wörterbuch\n",
    "for word in opinion_lexicon.positive():\n",
    "        word_dict[word] = pos_score\n",
    "        \n",
    "# Hinzufügen der negativen Wörter zum Wörterbuch\n",
    "for word in opinion_lexicon.negative():\n",
    "        word_dict[word] = neg_score\n",
    "        \n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "    for word in bag_of_words:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / len(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188097</th>\n",
       "      <td>B00099QWOU</td>\n",
       "      <td>As expected</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184654</th>\n",
       "      <td>B000RW1XO8</td>\n",
       "      <td>Works as designed...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin                  text  Bing_Liu_Score\n",
       "188097  B00099QWOU           As expected            0.00\n",
       "184654  B000RW1XO8  Works as designed...            0.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Bing_Liu_Score'] = df['text'].apply(bing_liu_score)\n",
    "df[['asin','text','Bing_Liu_Score']].sample(2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.587784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.427183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.345291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.529736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Bing_Liu_Score\n",
       "overall                \n",
       "1             -0.587784\n",
       "2             -0.427183\n",
       "4              0.345291\n",
       "5              0.529736"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Bing_Liu_Score'] = preprocessing.scale(df['Bing_Liu_Score'])\n",
    "df.groupby('overall').agg({'Bing_Liu_Score':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ansätze des überwachten Lernens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbereitung von Daten für einen überwachten Lernansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50820</th>\n",
       "      <td>True</td>\n",
       "      <td>B00BUIG6OK</td>\n",
       "      <td>Nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55604</th>\n",
       "      <td>True</td>\n",
       "      <td>B00HC2EY9W</td>\n",
       "      <td>The stickiness does not hold as well on the recent purchase as the first ones I bought.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252495</th>\n",
       "      <td>True</td>\n",
       "      <td>B000NW4PJC</td>\n",
       "      <td>Easy to install and great quality.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        verified        asin  \\\n",
       "50820       True  B00BUIG6OK   \n",
       "55604       True  B00HC2EY9W   \n",
       "252495      True  B000NW4PJC   \n",
       "\n",
       "                                                                                           text  \\\n",
       "50820                                                                                    Nasty.   \n",
       "55604   The stickiness does not hold as well on the recent purchase as the first ones I bought.   \n",
       "252495                                                       Easy to install and great quality.   \n",
       "\n",
       "        sentiment  \n",
       "50820           0  \n",
       "55604           0  \n",
       "252495          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)  ###\n",
    "pd.set_option('display.max_columns', None)  ###\n",
    "pd.set_option('display.width', None)  ###\n",
    "pd.set_option('display.max_colwidth', None)  ###\n",
    "\n",
    "file = \"reviews_5_balanced.json.gz\"\n",
    "file = f\"{BASE_DIR}/data/amazon-product-reviews/reviews_5_balanced.json.gz\" \n",
    "df = pd.read_json(file, lines=True)\n",
    "df = df.rename(columns={'reviewText': 'text'})  ###\n",
    "\n",
    "# Zuweisung eines neuen Zielklassen Lables [1,0] auf der Grundlage der Produktbewertung\n",
    "df['sentiment'] = 0\n",
    "df.loc[df['overall'] > 3, 'sentiment'] = 1\n",
    "df.loc[df['overall'] < 3, 'sentiment'] = 0\n",
    "\n",
    "# Unnötige Spalten entfernen, um einen einfachen Data Frame zu erhalten \n",
    "df.drop(columns=[\n",
    "    'reviewTime', 'unixReviewTime', 'overall', 'reviewerID', 'summary'],\n",
    "        inplace=True)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blueprint 2: Vektorisierung von Textdaten und Anwendung von überwachtem Lernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blueprints.preparation import clean\n",
    "df['text_orig'] = df['text'].copy()\n",
    "df['text'] = df['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durchführung der Tokenisierung und Lemmatisierung durch Wiederverwendung des Blueprints aus Kapitel 4 \n",
    "# Dies kann aufgrund des Umfangs des Datensatzes länger dauern\n",
    "import textacy\n",
    "import spacy\n",
    "from spacy.lang.en import STOP_WORDS as stop_words\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_lemmas(doc, **kwargs):\n",
    "    return [t.lemma_ for t in textacy.extract.words(doc,\n",
    "                                                    filter_stops = False,\n",
    "                                                    filter_punct = True,\n",
    "                                                    filter_nums = True,\n",
    "                                                    include_pos = ['ADJ', 'NOUN', 'VERB', 'ADV'],\n",
    "                                                    exclude_pos = None,\n",
    "                                                    min_freq = 1)]\n",
    "\n",
    "def clean_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = extract_lemmas(doc)\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kleme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kleme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kleme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Alternative Methode, die Wordnet POS-Tags anstelle von SpaCy verwendet - kann bei ähnlicher Genauigkeit schneller ablaufen\n",
    "# Tokenisierung und Lemmatisierung unter Verwendung von wordnet. Wiederverwendung von Teilen des Blueprints aus Kapitel 4\n",
    "# Verwendet wordnet POS-Tags anstelle von spaCy\n",
    "# den Wert, der dem POS-Tag entspricht, des wordnet-Objekts zurückgeben\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Text in Kleinbuchstaben umwandlenlower text\n",
    "    text = text.lower()\n",
    "    # Text tokenisieren und Satzzeichen entfernen\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # Wörter, die Zahlen enthalten, entferne\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # Stoppwörter entfernen\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # leere Token entfernen\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # POS-Tags rezeugen\n",
    "    pos_tags = pos_tag(text)\n",
    "    # Text lemmatisieren\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # Wörter mit nur einem Buchstaben entfernen\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # alle verbinden\n",
    "    text = \" \".join(text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Achtung! Dauert lange!\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "## Entfernung aller Annotationen, die nach dem Reinigungsschritt leer sind\n",
    "df = df[df['text'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Aufteilung in Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Data  234108\n",
      "Size of Test Data  58527\n",
      "Distribution of classes in Training Data :\n",
      "Positive Sentiment  50.90770071932612\n",
      "Negative Sentiment  49.09229928067388\n",
      "Distribution of classes in Testing Data :\n",
      "Positive Sentiment  50.9081278726058\n",
      "Negative Sentiment  49.09187212739419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],\n",
    "                                                    df['sentiment'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['sentiment'])\n",
    "\n",
    "print ('Size of Training Data ', X_train.shape[0])\n",
    "print ('Size of Test Data ', X_test.shape[0])\n",
    "\n",
    "print ('Distribution of classes in Training Data :')\n",
    "print ('Positive Sentiment ', str(sum(Y_train == 1)/ len(Y_train) * 100.0))\n",
    "print ('Negative Sentiment ', str(sum(Y_train == 0)/ len(Y_train) * 100.0))\n",
    "\n",
    "print ('Distribution of classes in Testing Data :')\n",
    "print ('Positive Sentiment ', str(sum(Y_test == 1)/ len(Y_test) * 100.0))\n",
    "print ('Negative Sentiment ', str(sum(Y_test == 0)/ len(Y_test) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Vektorisierung von Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,1))\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 4: Training des Machine Learning-Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=42, tol=1e-05)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model1 = LinearSVC(random_state=42, tol=1e-5)\n",
    "model1.fit(X_train_tf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score -  0.8658396979172006\n",
      "ROC-AUC Score -  0.8660667427476778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Y_pred = model1.predict(X_test_tf)\n",
    "print ('Accuracy Score - ', accuracy_score(Y_test, Y_pred))\n",
    "print ('ROC-AUC Score - ', roc_auc_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample reviews with their sentiment - \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_orig</th>\n",
       "      <th>sentiment_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29500</th>\n",
       "      <td>Its a nice night light, but not much else apparently!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98387</th>\n",
       "      <td>Way to small, do not know what to do with them or how to use them</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113648</th>\n",
       "      <td>Didn't make the room \"blue\" enough - returned with no questions asked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281527</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233713</th>\n",
       "      <td>fit like oem and looks good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    text_orig  \\\n",
       "29500                   Its a nice night light, but not much else apparently!   \n",
       "98387       Way to small, do not know what to do with them or how to use them   \n",
       "113648  Didn't make the room \"blue\" enough - returned with no questions asked   \n",
       "281527                                                              Excellent   \n",
       "233713                                            fit like oem and looks good   \n",
       "\n",
       "        sentiment_prediction  \n",
       "29500                      1  \n",
       "98387                      0  \n",
       "113648                     0  \n",
       "281527                     1  \n",
       "233713                     1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_reviews = df.sample(5, random_state=22)\n",
    "sample_reviews_tf = tfidf.transform(sample_reviews['text'])\n",
    "sentiment_predictions = model1.predict(sample_reviews_tf)\n",
    "sentiment_predictions = pd.DataFrame(data = sentiment_predictions,\n",
    "                                     index=sample_reviews.index,\n",
    "                                     columns=['sentiment_prediction'])\n",
    "sample_reviews = pd.concat([sample_reviews, sentiment_predictions], axis=1)\n",
    "print ('Some sample reviews with their sentiment - ')\n",
    "sample_reviews[['text_orig','sentiment_prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7525073897517385\n"
     ]
    }
   ],
   "source": [
    "def baseline_scorer(text):\n",
    "    score = bing_liu_score(text)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "Y_pred_baseline = X_test.apply(baseline_scorer)\n",
    "acc_score = accuracy_score(Y_pred_baseline, Y_test)\n",
    "print (acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speichern des trainierten Modells und des Vektorisierers zur späteren Verwendung mit der API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model1, open('models/sentiment_classification.pickle','wb'))\n",
    "pickle.dump(tfidf, open('models/sentiment_vectorizer.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorgefertigte Sprachmodelle mit Deep Learning (wieder-)verwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blueprint 3: Transfer-Learning-Techniken und vorab trainiertes Sprachmodell verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dies ist ein optionaler Schritt, um den Umfang der Daten zu reduzieren, indem nur 40 % der Beobachtungen in die \n",
    "# Stichprobe aufgenommen werden. ACHTUNG!Eine größere Anzahl von Beobachtungen kann zu einer längeren Laufzeit und \n",
    "# zum automatischen Herunterfahren der Colab Free-Instanz führen.\n",
    "df = df.sample(frac=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Laden von Modellen und Tokenisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kleme\\anaconda3\\envs\\NLP_Blueprints\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', finetuning_task='binary')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sentence I want embeddings for.\n",
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2015, 2005, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Es gibt eine Änderung im Verhalten der Abtrennung beim Aufruf der Encode-Funktion.\n",
    "# Dies führt zu einer Warnung und das Verhalten wird sich wahrscheinlich in Zukunft ändern\n",
    "# Derzeit wird die Warnung wie beschrieben unterdrückt - https://github.com/huggingface/transformers/issues/5397\n",
    "import warnings; ###\n",
    "warnings.filterwarnings('ignore'); ###\n",
    "\n",
    "def get_tokens(text, tokenizer, max_seq_length, add_special_tokens=True):\n",
    "  input_ids = tokenizer.encode(text, \n",
    "                               add_special_tokens=add_special_tokens, \n",
    "                               max_length=max_seq_length,\n",
    "                               pad_to_max_length=True)\n",
    "  attention_mask = [int(id > 0) for id in input_ids]\n",
    "  assert len(input_ids) == max_seq_length\n",
    "  assert len(attention_mask) == max_seq_length\n",
    "  return (input_ids, attention_mask)\n",
    "\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "input_ids, attention_mask = get_tokens(text, \n",
    "                                       tokenizer, \n",
    "                                       max_seq_length=30, \n",
    "                                       add_special_tokens = True)\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print (text)\n",
    "print (input_tokens)\n",
    "print (input_ids)\n",
    "print (attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text_orig'],\n",
    "                                                    df['sentiment'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['sentiment'])\n",
    "X_train_tokens = X_train.apply(get_tokens, args=(tokenizer, 50))\n",
    "X_test_tokens = X_test.apply(get_tokens, args=(tokenizer, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([93643, 50])\n",
      "torch.Size([93643, 50])\n",
      "torch.Size([93643])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "input_ids_train = torch.tensor(\n",
    "    [features[0] for features in X_train_tokens.values], dtype=torch.long)\n",
    "input_mask_train = torch.tensor(\n",
    "    [features[1] for features in X_train_tokens.values], dtype=torch.long)\n",
    "label_ids_train = torch.tensor(Y_train.values, dtype=torch.long)\n",
    "\n",
    "print (input_ids_train.shape)\n",
    "print (input_mask_train.shape)\n",
    "print (label_ids_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101, 10140,  2021,  2074,  2205,  2235,  2130,  2005, 10514,  9468,\n",
       "        27581,  2015,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train,input_mask_train,label_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = torch.tensor([features[0] for features in X_test_tokens.values], \n",
    "                              dtype=torch.long)\n",
    "input_mask_test = torch.tensor([features[1] for features in X_test_tokens.values], \n",
    "                               dtype=torch.long)\n",
    "label_ids_test = torch.tensor(Y_test.values, \n",
    "                              dtype=torch.long)\n",
    "test_dataset = TensorDataset(input_ids_test, input_mask_test, label_ids_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Trainierne des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples =  93643\n",
      "Num Epochs =  2\n",
      "Total train batch size  =  64\n",
      "Total optimization steps =  732\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "train_batch_size = 64\n",
    "num_train_epochs = 2\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              sampler=train_sampler, \n",
    "                              batch_size=train_batch_size)\n",
    "t_total = len(train_dataloader) // num_train_epochs\n",
    "\n",
    "print (\"Num examples = \", len(train_dataset))\n",
    "print (\"Num Epochs = \", num_train_epochs)\n",
    "print (\"Total train batch size  = \", train_batch_size)\n",
    "print (\"Total optimization steps = \", t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "learning_rate = 1e-4\n",
    "adam_epsilon = 1e-8\n",
    "warmup_steps = 0\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dde0c5f8304065a1c52b4dfbaca116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 1/2 [3:27:27<3:27:27, 12447.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb84587b69c4786b3a72a0bef45c13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [6:47:43<00:00, 12231.68s/it]  \n"
     ]
    }
   ],
   "source": [
    "### Achtung!!! Dauert sehr, sehr lange!!!\n",
    "\n",
    "\n",
    "from tqdm import trange, notebook\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
    "\n",
    "## Modell in den Modus 'trainieren' versetzen\n",
    "model.train()\n",
    "    \n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = notebook.tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "        ## Alle Gradienten zu Beginn jeder Iteration zurücksetzen\n",
    "        model.zero_grad()\n",
    "        \n",
    "        ## HINWEIS zur Beschleunigung: Setzen Sie das Modell und die eingegebenen Beobachtungen auf die GPU\n",
    "        model.to(device)\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        ## Identifizieren Sie die Inputs für das Modell\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        ## Vorwärtsdurchlauf durch das Modell. Eingabe -> Modell -> Ausgabe\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        ## Bestimmen Sie die Abweichung (Verlust)\n",
    "        loss = outputs[0]\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "        ## Rückproportionierung des Verlustes (automatische Berechnung von Gradienten)\n",
    "        loss.backward()\n",
    "\n",
    "        ## Verhinderung explodierender Gradienten durch Begrenzung der Gradienten auf 1,0 \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        ## Aktualisierung der Parameter und der Lernrate\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Modellbewertung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d772233a3914848918e45b82d973893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test data  0.9483148947076161\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "test_batch_size = 64\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             sampler=test_sampler, \n",
    "                             batch_size=test_batch_size)\n",
    "\n",
    "# Laden Sie das zuvor gespeicherte, trainierte Modell \n",
    "model = model.from_pretrained('outputs') ###\n",
    "\n",
    "# Initialisierung der Vorhersage und der tatsächlichen Kennzeichnungen\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "\n",
    "## Modell in den \"eval\"-Modus versetzen\n",
    "model.eval()\n",
    "\n",
    "for batch in notebook.tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "    \n",
    "    ## Setzen Sie das Modell und die eingegebenen Beobachtungen auf die GPU\n",
    "    model.to(device)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    ## Keine Gradienten verfolgen, da im 'eval'-Modus\n",
    "    with torch.no_grad():\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        ## Vorwärtsdurchlauf durch das Modell\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        ## Wir erhalten Verlust, da wir die Labels bereitgestellt haben\n",
    "        tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "        ## Der Testdatensatz enthält möglicherweise mehr als eine Batch von Artikeln.\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, \n",
    "                                      inputs['labels'].detach().cpu().numpy(), \n",
    "                                      axis=0)\n",
    "    \n",
    "## Endgültiger Verlust, Vorhersagen und Genauigkeit\n",
    "preds = np.argmax(preds, axis=1)\n",
    "acc_score = accuracy_score(preds, out_label_ids)\n",
    "print ('Accuracy Score on Test data ', acc_score)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
